\documentclass[dissertation.tex]{subfiles}
\begin{document}
\chapter{Conclusions}\label{cha:conclusions}
In this chapter we describe the evidence that emerges from the tests.
Furthermore, we discuss possible future improvements of the project.

\section{Tests analysis}
We present three scenes to do the tests. Scene \sceneA consists
in 10 obstacles randomly disposed, scene \sceneAb is the same scene
with a more dense graph, scene \sceneB has 100 obstacles and scene
\sceneC has 
only one bucket-shaped obstacle. 

We set the starting and ending points
to be at the extremes of the bounding box for scene \sceneA and scene
\sceneAb - 
i.e. the purpose of the tests in these scenes is to cross the area
with the obstacles. For scene \sceneB, we set the starting point in the
centre of the crowded area and the aim is to manage to exit
from the area. For scene \sceneC, we set the starting point inside the bucket
and we want to arrive under it.

Starting with the test for methods \metA and \metB, we manage to test
all the possible configurations of scenes, degree, method,
post-processing and knot partition. For method \metC, we tested 5
different 
parameter sets for the \acf{SA}.

Regarding the performances, the fastest method is \metB - to have an
idea of the temporal scales, consider that, on a quad core Intel
i5-2430M CPU at 2.40GHz with 8 Gb of RAM, an execution in scene
\sceneA with post processing and adaptive knot partitions takes:
\begin{itemize}
\item 76 seconds for method \metA;
\item 11 seconds for method \metB.
\end{itemize}
Method \metB is faster than method \metA, but we have to take into
consideration that method \metB is more refined than method \metA
because the 
latter needs to rebuild $G_t$ when connecting the start and ending points.

It is difficult to compare method \metC to the previous two because
of the different
parameter sets, however, an execution of it in scene \sceneA with
configuration \annA takes 168 seconds.

First of all, we notice that the application of the adaptive partition
results in a deterioration of the curvature plots - i.e. an increase
in magnitude
of the curvature peaks - for the experiments with scenes \sceneA,
\sceneAb and \sceneB. However the experiments with scene \sceneC result in an
improvement. Thus, this method is not always reliable in terms
of the curve fairing.

We notice that the curvature presents peaks near the start and/or the
end on some tests. See for instance tests 1, 3, 5. The cause of this
is the attachment method of start and ending points. In fact they are
attached to the nearest vertex of $G$, but it can be also too close
and in a bad direction, adding a deleterious hook to the control polygon.

The post-processing fulfills the
purpose of simplifying the path. Consider, for instance, test 33
(\cref{fig:test33}) where the curvature plot has different
peaks. After the application of post-processing, we obtain test 34
(\cref{fig:test34}) where the curvature peaks are mitigated.

The degree increase algorithm is improving the
curvature: the plots are continuous for degree 3 and continuous and
smooth for degree 4. Unfortunately, it is not reliable for the torsion
(not shown in the tests) because, by adding aligned vertices, we force
plane changes on zero-curvature points, where the torsion is not
defined.

Method \metC produces high quality curves (see tests from 74 to 99)
with low peaks of curvature and torsion. Moreover, this solution is
not conditioned by the problem in degree increase mentioned before,
the plots of the torsion are good.

An disadvantage of this
solution is the discretization of collision check. Thus,
depending on the parameters, it is possible that the path intersects
an obstacle without noticing it.
Other disadvantages are the slower
execution time and the difficulty in finding the right values of the
annealing parameters. In fact, wrong values of warming, or an
insufficient number of
trials can \emph{freeze} the system in a not optimal
status. Furthermore, it is necessary to adapt the parameters to
different problems. For instance, the configuration \annB and \annC are
not fitted for tests from 94 to 99: using those settings is not enough
to let the system converge in an admissible state.

Regarding the complexity, we have that the highest cost which is
$\bigO(|O|\log|O|)$ in the number of obstacles $|O|$, comes from the
creation of the scene. A run on the scene have complexity
\begin{itemize}
\item $\bigO(|O|\log|O|)$ for method \metA;
\item $\bigO(|O|\log|O|+|P||O|)$ for method \metB, where $|P|$ is the
  number of vertices in the control polygon;
\item $\bigO(|O|\log|O|+len(P)|O|)$ for method \metC, where $len(P)$
  is the length of the control polygon.
\end{itemize}

\section{Future improvements}
The present work contemplates many possible improvements. One of them
is to provide a better method to attach the start and ending
points. For instance one possibility is to connect them to all the
visible vertices of $G$.

Another possible improvement is to design another algorithm for the
adaptive knot partition. The current one does not improve enough the
fairness of the curve.

Considering the different benefits and drawbacks of the implemented
solutions, would be interesting to further elaborate the idea of a
mixed approach to the 
problem: analytical and stochastic.

An new interesting solution might be implementing a
stochastic optimization on the path obtained from solution 1 or
solution 2, that is obstacle-free guaranteed. This hypothetical stochastic
optimization must avoid states that violates the \acf{CHP}, and it can
work directly on the state space without the Lagrangian
relaxation. In fact, in that scenario the initial status is already
obstacle-free. Furthermore, we believe that the optimization process do
not need to explore too much the state space trespassing obstacle
zones.

We believe that the described process can be very effective in
improving curvature, torsion and length of the path. It can obtain
curves with the quality of the implemented third solution and without the
disadvantages of it: the slow computation and the possible collision
errors caused by the discretization of the inclusion checks.

Another improvement could be studying different basic structures
besides the graph extract from \acf{VD}. For instance, \acf{RRT}.
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../dissertation"
%%% End:
